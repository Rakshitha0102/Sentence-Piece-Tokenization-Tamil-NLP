
# ğŸ§  SentencePiece Tokenization on Tamil Dataset

This project demonstrates how to apply **SentencePiece**, an unsupervised subword tokenizer, to a **Tamil language dataset**. It showcases how subword tokenization can improve preprocessing in low-resource or morphologically rich languages like Tamil.

---

## ğŸ“ File Structure

```
.
â”œâ”€â”€ Spt.ipynb              # Main notebook for SentencePiece tokenization
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ tamil_dataset/         # Folder containing Tamil text data (optional)
â””â”€â”€ requirements.txt       # Required Python packages
```

---

## ğŸš€ Features

- ğŸ“š Load and preprocess raw Tamil text data
- âœ‚ï¸ Train SentencePiece tokenizer using BPE or Unigram
- ğŸ§± Tokenize and detokenize Tamil sentences
- ğŸ“Š Visualize vocabulary and token frequency
- ğŸ’¾ Save and reuse trained tokenizers

---

## ğŸ§ª How to Run

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/tamil-sentencepiece.git
cd tamil-sentencepiece
```

### 2. Install required libraries

```bash
pip install -r requirements.txt
```

Or manually install:

```
sentencepiece
pandas
matplotlib
seaborn
```

### 3. Launch the notebook

```bash
jupyter notebook Spt.ipynb
```

---

## ğŸ§° Tools Used

- ğŸ§  **SentencePiece** â€“ Subword tokenizer (BPE/Unigram)
- ğŸ“Š **Matplotlib & Seaborn** â€“ Token frequency visualization
- ğŸ¼ **Pandas** â€“ Dataset handling

---
